{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "PoI3cPC-pOTU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import euclidean\n",
        "from transformers import AutoTokenizer, AutoModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "1Iz9LrK_pzdr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(sentence, tokenizer, model):\n",
        "    # Преобразование предложения в последовательность токенов\n",
        "    tokens = tokenizer.encode(sentence, add_special_tokens=True)\n",
        "    # Получение выходных эмбеддингов для каждого токена\n",
        "    outputs = model(torch.tensor([tokens]))[0]\n",
        "    # Усреднение эмбеддингов для получения единственного эмбеддинга для всего предложения\n",
        "    embedding = torch.mean(outputs, dim=1).squeeze().detach().numpy()\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "YhdLBnVlp13A"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1_ru = \"Машины обучаются быстрее, чем когда-либо.\"\n",
        "sentence2_ru = \"Искусственный интеллект меняет наш мир.\"\n",
        "\n",
        "sentence3_ru = \"Быстрые обучающие модели.\"\n",
        "sentence4_ru = \"Коты и собаки являются домашними питомцами.\"\n",
        "\n",
        "embedding1_ru = get_embedding(sentence1_ru, tokenizer, model)\n",
        "embedding2_ru = get_embedding(sentence2_ru, tokenizer, model)\n",
        "\n",
        "embedding3_ru = get_embedding(sentence3_ru, tokenizer, model)\n",
        "embedding4_ru = get_embedding(sentence4_ru, tokenizer, model)"
      ],
      "metadata": {
        "id": "stbRqhGaqAnQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance1_ru = euclidean(embedding1_ru, embedding2_ru)\n",
        "distance2_ru = euclidean(embedding3_ru, embedding4_ru)\n",
        "\n",
        "print(f\"Семантически похожие строки: {distance1_ru}\")\n",
        "print(f\"Семантически разные строки: {distance2_ru}\")\n",
        "print(f\"Евклидово расстояние между эмбеддингами для семантически похожих строк {'меньше' if distance1_ru < distance2_ru else 'больше'}, чем для двух семантически отличных строк. (ru)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2r4QOK3qCvy",
        "outputId": "0b46570e-7217-4133-892a-25b484242901"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Семантически похожие строки: 10.171270370483398\n",
            "Семантически разные строки: 11.817597389221191\n",
            "Евклидово расстояние между эмбеддингами для семантически похожих строк меньше, чем для двух семантически отличных строк. (ru)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence1_en = \"It is only with the heart that one can see rightly.\"\n",
        "sentence2_en = \"One can become a writer only if he is talented.\"\n",
        "\n",
        "sentence3_en = \"It seems that you have made a rude mistake.\"\n",
        "sentence4_en = \"My car won't start.\"\n",
        "\n",
        "embedding1_en = get_embedding(sentence1_en, tokenizer, model)\n",
        "embedding2_en = get_embedding(sentence2_en, tokenizer, model)\n",
        "\n",
        "embedding3_en = get_embedding(sentence3_en, tokenizer, model)\n",
        "embedding4_en = get_embedding(sentence4_en, tokenizer, model)"
      ],
      "metadata": {
        "id": "meKWqvX1bEa6"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distance1_en = euclidean(embedding1_en, embedding2_en)\n",
        "distance2_en = euclidean(embedding3_en, embedding4_en)\n",
        "\n",
        "print(f\"Семантически похожие строки: {distance1_en}\")\n",
        "print(f\"Семантически разные строки: {distance2_en}\")\n",
        "print(f\"Евклидово расстояние между эмбеддингами для семантически похожих строк {'меньше' if distance1_en < distance2_en else 'больше'}, чем для двух семантически отличных строк. (en)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtwPMejbbGGZ",
        "outputId": "b717be29-ec95-4176-d026-25f317792288"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Семантически похожие строки: 15.462054252624512\n",
            "Семантически разные строки: 11.976407051086426\n",
            "Евклидово расстояние между эмбеддингами для семантически похожих строк больше, чем для двух семантически отличных строк. (en)\n"
          ]
        }
      ]
    }
  ]
}